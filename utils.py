import os
import re
import random
import logging
from typing import List
import matplotlib.pyplot as plt

import numpy as np
import torch


def save_attention_map(attn_map, fields, text, img_name):
    """ save attention map """
    attn_map = attn_map.cpu().numpy()
    attn_map = attn_map[:len(text), :len(fields)]
    attn_map = attn_map / (attn_map.max(axis=1)[:, None] + 0.001)  # normalize

    plt.clf()
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(1, 1, 1)
    ax.imshow(attn_map, interpolation='nearest', cmap='Blues')

    ax.set_xticks(range(len(fields)))  # x-axis: fields
    ax.set_xticklabels(fields, rotation=75)
    ax.set_yticks(range(len(text)))  # y-axis: text
    ax.set_yticklabels(text)

    plt.savefig('./results/imgs/' + str(img_name) + '.png')


def save_checkpoint(experiment_time, model, optimizer):
    check_file_exist('./results/checkpoints')
    checkpoint_path = './results/checkpoints/' + experiment_time + '.pth'
    checkpoint = {
        'model': model.state_dict(),
        'optimizer': optimizer.state_dict()
    }
    torch.save(checkpoint, checkpoint_path)


def load_checkpoint(latest, file_name=None):
    """ load the latest checkpoint """
    checkpoints_dir = './results/checkpoints'
    if latest:
        file_list = os.listdir(checkpoints_dir)
        file_list.sort(key=lambda fn: os.path.getmtime(
            checkpoints_dir + '/' + fn))
        checkpoint = torch.load(checkpoints_dir + '/' + file_list[-1])
        return checkpoint, str(file_list[-1])
    else:
        if file_name is None:
            raise ValueError('checkpoint_path cannot be empty!')
        checkpoint = torch.load(checkpoints_dir + '/' + file_name)
        return checkpoint, file_name


def fix_seed(seed):
    """ set random seed to ensure reproducibility """
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)


def count_parameters(net: torch.nn.Module):
    """ count all the parameters in the model """
    return sum(p.numel() for p in net.parameters() if p.requires_grad)


def get_logger(filename, verbosity=1, name=None):
    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}
    formatter = logging.Formatter(" %(message)s")
    logger = logging.getLogger(name)
    logger.setLevel(level_dict[verbosity])
    fh = logging.FileHandler(filename, "a")
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    sh = logging.StreamHandler()
    sh.setFormatter(formatter)
    logger.addHandler(sh)
    return logger


def record_time(start_time, end_time):
    """ get minute & second-level measurement of the asc-time """
    elapsed_time = end_time - start_time
    elapsed_min = int(elapsed_time / 60)
    elapsed_sec = int(elapsed_time - (elapsed_min * 60))
    return elapsed_min, elapsed_sec


def check_file_exist(file_path):
    if not os.path.exists(file_path):
        os.mkdir(file_path)


def random_list(start: int, stop: int, length: int):
    """ make a random list between (start, end) in param:length """
    rand_list: List[int] = []
    while len(rand_list) < length:
        rand_number = random.randint(start, stop)
        if rand_number not in rand_list:
            rand_list.append(rand_number)
    return sorted(rand_list)


def show_plot(plt_in, tag, mode):
    plt.figure()
    plt.plot(plt_in)
    plt.xlabel('epoch')
    plt.ylabel(tag)
    plt.legend([mode], loc='upper left')
    plt.show()


def show_loss_plot(plot_loss_train, plot_loss_dev):
    plt.figure()
    plt.plot(plot_loss_train)
    plt.plot(plot_loss_dev)
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'dev'], loc='upper left')
    plt.show()


def get_latest_file(target_dir):
    file_list = os.listdir(target_dir)
    file_list.sort(key=lambda fn: os.path.getmtime(target_dir + '/' + fn))
    latest_file = target_dir + '/' + file_list[-1]
    return latest_file


def clean_logs(latest=True, file_name=None):
    """ clean chaotic logs generated by pyrouge """
    if latest:
        cleaned_logs = []
        latest_log = get_latest_file('./results/logs')
        with open(latest_log, 'r') as f:
            log = f.readlines()
        for line in log:
            if '.txt' not in line:
                cleaned_logs.append(line)
        with open(latest_log, 'w') as f:
            for line in cleaned_logs:
                f.write(line)
    else:
        if file_name is None:
            raise ValueError('file_path cannot be empty!')
        with open('./results/logs/' + file_name, 'r') as f:
            log = f.readlines()
        cleaned_logs = []
        for line in log:
            if '.txt' not in line:
                cleaned_logs.append(line)
        with open('./results/logs/' + file_name, 'w') as f:
            for line in cleaned_logs:
                f.write(line)


def analyze_log(latest=True, file_name=None):
    if latest:
        latest_log = get_latest_file('./results/logs')
        with open(latest_log, 'r') as f:
            log = f.readlines()
    else:
        if file_name is None:
            raise ValueError('file_path cannot be empty!')
        with open('./results/logs/' + file_name, 'r') as f:
            log = f.readlines()

    train_loss, dev_loss, score_dict = [], [], []
    for line in log:
        if 'train_loss' in line:
            train_loss.append(
                float(re.sub('=', '', line.split('train_loss')[1]).split()[0]))
            dev_loss.append(
                float(re.sub('=', '', line.split('valid_loss')[1]).split()[0]))

        # if 'bleu_score' in line or 'bleu score' in line:
        #     score_dict.append(float(line[-6:]))

    show_loss_plot(train_loss, dev_loss)
    # show_plot(plt_in=score_dict, tag='bleu_score', mode='test')
